{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5f11e7-b3bd-478d-b557-5b1e861edd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: protobuf==3.11 in /home/indika/anaconda3/envs/myenv/lib/python3.8/site-packages (3.11.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/indika/.local/lib/python3.8/site-packages (from protobuf==3.11) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/indika/anaconda3/envs/myenv/lib/python3.8/site-packages (from protobuf==3.11) (58.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/indika/anaconda3/envs/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install protobuf==3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b4a3d4-b21c-4992-a1ba-5f085a8ecc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46587f90-4b58-46e6-9fe2-9812d8f3c7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fb87ec-3b47-4d9b-a9af-896f38c50577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d870d2-7a17-4aa7-bfa3-5b1dfd09477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1+cu111 0.10.1+cu111\n"
     ]
    }
   ],
   "source": [
    "# Version\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2b8d4d-820e-4127-b246-f791f063d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "def load_data(data=data, test=False):\n",
    "    if test is True:\n",
    "        if \"data.npy\" in os.listdir(\"./\"):\n",
    "            data = np.load(\"./data.npy\", allow_pickle=True)[:500]\n",
    "            return data\n",
    "    if \"data.npy\" in os.listdir(\"./\"):\n",
    "        data = np.load(\"./data.npy\", allow_pickle=True)\n",
    "        return data\n",
    "    new_data = []\n",
    "    for idx in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[idx]\n",
    "        xmin, ymin, xmax, ymax = info[\"xmin\"], info[\"ymin\"], info[\"xmax\"], info[\"ymax\"]\n",
    "        height, width = cv2.imread(\"./data/\" + info[\"image\"]).shape[:2]\n",
    "        record[\"file_name\"] = \"./data/\" + info[\"image\"]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"cateogry_id\"] = 0\n",
    "        objs = [\n",
    "            {\n",
    "                \"bbox\": [info[\"xmin\"], info[\"ymin\"], info[\"xmax\"], info[\"ymax\"]],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "        ]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"annotations\"] = objs\n",
    "        new_data.append(record)\n",
    "    np.save(\"data.npy\", new_data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc33c998-6463-4b59-9abd-9c99693f6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "labels = [\"Card\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93234b89-0bb9-4153-83e0-da231b28a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the data\n",
    "DatasetCatalog.register(\"data\", lambda: load_data())\n",
    "MetadataCatalog.get(\"data\").set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get(\"data\")\n",
    "DatasetCatalog.register(\"test\", lambda: load_data(test=True))\n",
    "MetadataCatalog.get(\"test\").set(thing_classes=labels)\n",
    "metadata_test = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17853a58-221a-47a8-9370-1792032b38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 63686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.00MB of 0.00MB uploaded (0.00MB deduped)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20211012_092641-3859g373/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20211012_092641-3859g373/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbaseline\u001b[0m: \u001b[34mhttps://app.wandb.ai/ranuga-d/uncategorized/runs/3859g373\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20211012_092749-jsfehlay\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbaseline\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ranuga-d/uncategorized\" target=\"_blank\">https://app.wandb.ai/ranuga-d/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ranuga-d/uncategorized/runs/jsfehlay\" target=\"_blank\">https://app.wandb.ai/ranuga-d/uncategorized/runs/jsfehlay</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m[10/12 09:27:56 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (6): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (7): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (8): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (9): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (10): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (11): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (12): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (13): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (14): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (15): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (16): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (17): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (18): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (19): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (20): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (21): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (22): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/12 09:27:56 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 559 images left.\n",
      "\u001b[32m[10/12 09:27:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/12 09:27:56 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/12 09:27:56 d2.data.common]: \u001b[0mSerializing 559 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 09:27:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 09:27:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/12 09:28:08 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 19  total_loss: 1.092  loss_cls: 0.6161  loss_box_reg: 0.4701  loss_rpn_cls: 0.003915  loss_rpn_loc: 0.004176  time: 0.4952  data_time: 0.0089  lr: 4.9953e-06  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:28:17 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 39  total_loss: 1.002  loss_cls: 0.5534  loss_box_reg: 0.4528  loss_rpn_cls: 0.002985  loss_rpn_loc: 0.006378  time: 0.4921  data_time: 0.0025  lr: 9.9902e-06  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:28:27 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 59  total_loss: 0.903  loss_cls: 0.4482  loss_box_reg: 0.4261  loss_rpn_cls: 0.006906  loss_rpn_loc: 0.00411  time: 0.4911  data_time: 0.0025  lr: 1.4985e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:28:37 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 79  total_loss: 0.8562  loss_cls: 0.3592  loss_box_reg: 0.4741  loss_rpn_cls: 0.007636  loss_rpn_loc: 0.004412  time: 0.4896  data_time: 0.0025  lr: 1.998e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:28:47 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 99  total_loss: 0.7193  loss_cls: 0.28  loss_box_reg: 0.408  loss_rpn_cls: 0.00638  loss_rpn_loc: 0.004395  time: 0.4901  data_time: 0.0026  lr: 2.4975e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:28:57 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 119  total_loss: 0.7911  loss_cls: 0.253  loss_box_reg: 0.5211  loss_rpn_cls: 0.002826  loss_rpn_loc: 0.004441  time: 0.4912  data_time: 0.0025  lr: 2.997e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:07 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 139  total_loss: 0.7016  loss_cls: 0.2033  loss_box_reg: 0.4947  loss_rpn_cls: 0.003433  loss_rpn_loc: 0.004936  time: 0.4914  data_time: 0.0024  lr: 3.4965e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:17 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 159  total_loss: 0.6755  loss_cls: 0.1866  loss_box_reg: 0.4898  loss_rpn_cls: 0.00711  loss_rpn_loc: 0.004247  time: 0.4923  data_time: 0.0026  lr: 3.996e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:27 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 179  total_loss: 0.6517  loss_cls: 0.1673  loss_box_reg: 0.4855  loss_rpn_cls: 0.003518  loss_rpn_loc: 0.00454  time: 0.4950  data_time: 0.0025  lr: 4.4955e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:37 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 199  total_loss: 0.6645  loss_cls: 0.1437  loss_box_reg: 0.5053  loss_rpn_cls: 0.00518  loss_rpn_loc: 0.003305  time: 0.4969  data_time: 0.0026  lr: 4.995e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:48 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 219  total_loss: 0.5993  loss_cls: 0.1362  loss_box_reg: 0.4544  loss_rpn_cls: 0.007732  loss_rpn_loc: 0.003237  time: 0.5001  data_time: 0.0025  lr: 5.4945e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:29:58 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 239  total_loss: 0.5912  loss_cls: 0.1253  loss_box_reg: 0.4803  loss_rpn_cls: 0.003853  loss_rpn_loc: 0.003158  time: 0.5024  data_time: 0.0026  lr: 5.994e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:08 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 259  total_loss: 0.6185  loss_cls: 0.1021  loss_box_reg: 0.4957  loss_rpn_cls: 0.002834  loss_rpn_loc: 0.003738  time: 0.5026  data_time: 0.0025  lr: 6.4935e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:19 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 279  total_loss: 0.5342  loss_cls: 0.08381  loss_box_reg: 0.4432  loss_rpn_cls: 0.001306  loss_rpn_loc: 0.003057  time: 0.5028  data_time: 0.0026  lr: 6.993e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:29 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 299  total_loss: 0.5528  loss_cls: 0.07889  loss_box_reg: 0.4518  loss_rpn_cls: 0.002048  loss_rpn_loc: 0.00297  time: 0.5029  data_time: 0.0026  lr: 7.4925e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:39 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 319  total_loss: 0.5177  loss_cls: 0.08672  loss_box_reg: 0.421  loss_rpn_cls: 0.002875  loss_rpn_loc: 0.002608  time: 0.5025  data_time: 0.0026  lr: 7.992e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:48 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 339  total_loss: 0.4959  loss_cls: 0.08025  loss_box_reg: 0.3967  loss_rpn_cls: 0.006113  loss_rpn_loc: 0.002294  time: 0.5018  data_time: 0.0027  lr: 8.4915e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:30:58 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 359  total_loss: 0.5083  loss_cls: 0.08412  loss_box_reg: 0.4248  loss_rpn_cls: 0.002216  loss_rpn_loc: 0.002225  time: 0.5012  data_time: 0.0026  lr: 8.991e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:08 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 379  total_loss: 0.4934  loss_cls: 0.06352  loss_box_reg: 0.4101  loss_rpn_cls: 0.002281  loss_rpn_loc: 0.003459  time: 0.5010  data_time: 0.0027  lr: 9.4905e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:18 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 399  total_loss: 0.4526  loss_cls: 0.06315  loss_box_reg: 0.3833  loss_rpn_cls: 0.002017  loss_rpn_loc: 0.003075  time: 0.5004  data_time: 0.0025  lr: 9.99e-05  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:28 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 419  total_loss: 0.442  loss_cls: 0.06618  loss_box_reg: 0.3548  loss_rpn_cls: 0.003006  loss_rpn_loc: 0.002634  time: 0.4998  data_time: 0.0026  lr: 0.0001049  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:38 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 439  total_loss: 0.4271  loss_cls: 0.05807  loss_box_reg: 0.3634  loss_rpn_cls: 0.001219  loss_rpn_loc: 0.001968  time: 0.5005  data_time: 0.0027  lr: 0.00010989  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:49 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 459  total_loss: 0.4114  loss_cls: 0.06745  loss_box_reg: 0.3188  loss_rpn_cls: 0.002414  loss_rpn_loc: 0.002702  time: 0.5017  data_time: 0.0034  lr: 0.00011489  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:31:59 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 479  total_loss: 0.3571  loss_cls: 0.06325  loss_box_reg: 0.2925  loss_rpn_cls: 0.002893  loss_rpn_loc: 0.003049  time: 0.5032  data_time: 0.0028  lr: 0.00011988  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:32:10 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 499  total_loss: 0.3381  loss_cls: 0.05594  loss_box_reg: 0.2804  loss_rpn_cls: 0.001819  loss_rpn_loc: 0.003738  time: 0.5043  data_time: 0.0032  lr: 0.00012488  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:32:20 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 519  total_loss: 0.3404  loss_cls: 0.05279  loss_box_reg: 0.2877  loss_rpn_cls: 0.001469  loss_rpn_loc: 0.003178  time: 0.5048  data_time: 0.0028  lr: 0.00012987  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:32:30 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 539  total_loss: 0.2774  loss_cls: 0.0628  loss_box_reg: 0.203  loss_rpn_cls: 0.001335  loss_rpn_loc: 0.002055  time: 0.5048  data_time: 0.0026  lr: 0.00013487  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:32:41 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 559  total_loss: 0.2572  loss_cls: 0.05445  loss_box_reg: 0.1988  loss_rpn_cls: 0.0008063  loss_rpn_loc: 0.002503  time: 0.5052  data_time: 0.0027  lr: 0.00013986  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:32:51 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 579  total_loss: 0.2824  loss_cls: 0.05735  loss_box_reg: 0.2221  loss_rpn_cls: 0.003199  loss_rpn_loc: 0.002491  time: 0.5056  data_time: 0.0026  lr: 0.00014486  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:01 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 599  total_loss: 0.2571  loss_cls: 0.05458  loss_box_reg: 0.2073  loss_rpn_cls: 0.00241  loss_rpn_loc: 0.002483  time: 0.5056  data_time: 0.0026  lr: 0.00014985  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:12 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 619  total_loss: 0.254  loss_cls: 0.06386  loss_box_reg: 0.1827  loss_rpn_cls: 0.001401  loss_rpn_loc: 0.002849  time: 0.5061  data_time: 0.0026  lr: 0.00015485  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:22 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 639  total_loss: 0.2658  loss_cls: 0.05527  loss_box_reg: 0.1922  loss_rpn_cls: 0.001788  loss_rpn_loc: 0.002528  time: 0.5062  data_time: 0.0027  lr: 0.00015984  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:32 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 659  total_loss: 0.2451  loss_cls: 0.0541  loss_box_reg: 0.1905  loss_rpn_cls: 0.00369  loss_rpn_loc: 0.002806  time: 0.5063  data_time: 0.0027  lr: 0.00016484  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:43 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 679  total_loss: 0.2532  loss_cls: 0.07075  loss_box_reg: 0.178  loss_rpn_cls: 0.0007732  loss_rpn_loc: 0.00222  time: 0.5067  data_time: 0.0029  lr: 0.00016983  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:33:53 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 699  total_loss: 0.2452  loss_cls: 0.05564  loss_box_reg: 0.1786  loss_rpn_cls: 0.001352  loss_rpn_loc: 0.002281  time: 0.5071  data_time: 0.0026  lr: 0.00017483  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:04 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 719  total_loss: 0.2784  loss_cls: 0.0465  loss_box_reg: 0.2135  loss_rpn_cls: 0.001034  loss_rpn_loc: 0.002613  time: 0.5079  data_time: 0.0026  lr: 0.00017982  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:14 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 739  total_loss: 0.2391  loss_cls: 0.05069  loss_box_reg: 0.1924  loss_rpn_cls: 0.001003  loss_rpn_loc: 0.00234  time: 0.5083  data_time: 0.0028  lr: 0.00018482  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:24 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 759  total_loss: 0.2517  loss_cls: 0.06904  loss_box_reg: 0.1714  loss_rpn_cls: 0.002791  loss_rpn_loc: 0.00265  time: 0.5078  data_time: 0.0028  lr: 0.00018981  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:35 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 779  total_loss: 0.2377  loss_cls: 0.04244  loss_box_reg: 0.1769  loss_rpn_cls: 0.0005304  loss_rpn_loc: 0.001724  time: 0.5077  data_time: 0.0028  lr: 0.00019481  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:45 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 799  total_loss: 0.2402  loss_cls: 0.04297  loss_box_reg: 0.1789  loss_rpn_cls: 0.001647  loss_rpn_loc: 0.002938  time: 0.5076  data_time: 0.0026  lr: 0.0001998  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:34:55 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 819  total_loss: 0.2458  loss_cls: 0.04337  loss_box_reg: 0.1834  loss_rpn_cls: 0.0005251  loss_rpn_loc: 0.001997  time: 0.5079  data_time: 0.0026  lr: 0.0002048  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:05 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 839  total_loss: 0.2527  loss_cls: 0.04958  loss_box_reg: 0.175  loss_rpn_cls: 0.001473  loss_rpn_loc: 0.002716  time: 0.5082  data_time: 0.0025  lr: 0.00020979  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:16 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 859  total_loss: 0.2551  loss_cls: 0.05064  loss_box_reg: 0.2146  loss_rpn_cls: 0.0002771  loss_rpn_loc: 0.002954  time: 0.5085  data_time: 0.0029  lr: 0.00021479  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:26 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 879  total_loss: 0.2912  loss_cls: 0.0626  loss_box_reg: 0.1797  loss_rpn_cls: 0.002264  loss_rpn_loc: 0.002409  time: 0.5084  data_time: 0.0027  lr: 0.00021978  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:36 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 899  total_loss: 0.2775  loss_cls: 0.07918  loss_box_reg: 0.1778  loss_rpn_cls: 0.0007868  loss_rpn_loc: 0.001864  time: 0.5083  data_time: 0.0026  lr: 0.00022478  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:46 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 919  total_loss: 0.2541  loss_cls: 0.06044  loss_box_reg: 0.1866  loss_rpn_cls: 0.0005369  loss_rpn_loc: 0.003163  time: 0.5081  data_time: 0.0026  lr: 0.00022977  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:35:57 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 939  total_loss: 0.2504  loss_cls: 0.06286  loss_box_reg: 0.1807  loss_rpn_cls: 0.001688  loss_rpn_loc: 0.002196  time: 0.5081  data_time: 0.0026  lr: 0.00023477  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:07 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 959  total_loss: 0.2552  loss_cls: 0.04893  loss_box_reg: 0.1865  loss_rpn_cls: 0.0004914  loss_rpn_loc: 0.002877  time: 0.5086  data_time: 0.0026  lr: 0.00023976  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:17 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 979  total_loss: 0.2621  loss_cls: 0.05961  loss_box_reg: 0.1899  loss_rpn_cls: 0.005087  loss_rpn_loc: 0.002492  time: 0.5087  data_time: 0.0027  lr: 0.00024476  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:28 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 999  total_loss: 0.253  loss_cls: 0.05592  loss_box_reg: 0.1863  loss_rpn_cls: 0.001147  loss_rpn_loc: 0.002791  time: 0.5089  data_time: 0.0026  lr: 0.00024975  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:38 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 1019  total_loss: 0.2769  loss_cls: 0.064  loss_box_reg: 0.1986  loss_rpn_cls: 0.001113  loss_rpn_loc: 0.001981  time: 0.5093  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:48 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 1039  total_loss: 0.2427  loss_cls: 0.05886  loss_box_reg: 0.1755  loss_rpn_cls: 0.0006083  loss_rpn_loc: 0.002244  time: 0.5091  data_time: 0.0033  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:36:58 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 1059  total_loss: 0.2091  loss_cls: 0.04931  loss_box_reg: 0.1488  loss_rpn_cls: 0.0005749  loss_rpn_loc: 0.001913  time: 0.5088  data_time: 0.0029  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:08 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 1079  total_loss: 0.2481  loss_cls: 0.04192  loss_box_reg: 0.1911  loss_rpn_cls: 0.0005234  loss_rpn_loc: 0.002206  time: 0.5084  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:18 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 1099  total_loss: 0.2526  loss_cls: 0.05712  loss_box_reg: 0.19  loss_rpn_cls: 0.0003815  loss_rpn_loc: 0.002738  time: 0.5079  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:28 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1119  total_loss: 0.2181  loss_cls: 0.04043  loss_box_reg: 0.1814  loss_rpn_cls: 0.000408  loss_rpn_loc: 0.002115  time: 0.5075  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:37 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 1139  total_loss: 0.2764  loss_cls: 0.05276  loss_box_reg: 0.2027  loss_rpn_cls: 0.002223  loss_rpn_loc: 0.001839  time: 0.5071  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:47 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 1159  total_loss: 0.219  loss_cls: 0.05569  loss_box_reg: 0.1556  loss_rpn_cls: 0.0007961  loss_rpn_loc: 0.001644  time: 0.5066  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:37:57 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 1179  total_loss: 0.2667  loss_cls: 0.05154  loss_box_reg: 0.2043  loss_rpn_cls: 0.0005688  loss_rpn_loc: 0.002279  time: 0.5062  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:07 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1199  total_loss: 0.214  loss_cls: 0.05264  loss_box_reg: 0.1578  loss_rpn_cls: 0.0003898  loss_rpn_loc: 0.001939  time: 0.5058  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:16 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 1219  total_loss: 0.2319  loss_cls: 0.05377  loss_box_reg: 0.1767  loss_rpn_cls: 0.0007667  loss_rpn_loc: 0.002027  time: 0.5056  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:26 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 1239  total_loss: 0.2335  loss_cls: 0.05446  loss_box_reg: 0.1927  loss_rpn_cls: 0.001943  loss_rpn_loc: 0.002402  time: 0.5054  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:36 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1259  total_loss: 0.2366  loss_cls: 0.05866  loss_box_reg: 0.16  loss_rpn_cls: 0.0002481  loss_rpn_loc: 0.001799  time: 0.5052  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:46 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 1279  total_loss: 0.2226  loss_cls: 0.05349  loss_box_reg: 0.1811  loss_rpn_cls: 0.0003442  loss_rpn_loc: 0.00221  time: 0.5049  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:38:56 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 1299  total_loss: 0.2427  loss_cls: 0.04934  loss_box_reg: 0.1851  loss_rpn_cls: 0.0009243  loss_rpn_loc: 0.001863  time: 0.5047  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:06 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 1319  total_loss: 0.2316  loss_cls: 0.0445  loss_box_reg: 0.1725  loss_rpn_cls: 0.002385  loss_rpn_loc: 0.001659  time: 0.5045  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:15 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 1339  total_loss: 0.2485  loss_cls: 0.06316  loss_box_reg: 0.1716  loss_rpn_cls: 0.001942  loss_rpn_loc: 0.0027  time: 0.5043  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:25 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 1359  total_loss: 0.2544  loss_cls: 0.04931  loss_box_reg: 0.1813  loss_rpn_cls: 0.001612  loss_rpn_loc: 0.002016  time: 0.5039  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:35 d2.utils.events]: \u001b[0m eta: 0:09:24  iter: 1379  total_loss: 0.2313  loss_cls: 0.04917  loss_box_reg: 0.1677  loss_rpn_cls: 0.0003221  loss_rpn_loc: 0.002947  time: 0.5036  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:44 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 1399  total_loss: 0.2547  loss_cls: 0.06239  loss_box_reg: 0.1986  loss_rpn_cls: 0.0005711  loss_rpn_loc: 0.002282  time: 0.5032  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:39:54 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1419  total_loss: 0.2504  loss_cls: 0.05492  loss_box_reg: 0.2011  loss_rpn_cls: 0.0003708  loss_rpn_loc: 0.001773  time: 0.5031  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:04 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 1439  total_loss: 0.2186  loss_cls: 0.0565  loss_box_reg: 0.1641  loss_rpn_cls: 0.0008086  loss_rpn_loc: 0.001948  time: 0.5030  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:14 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 1459  total_loss: 0.2257  loss_cls: 0.04596  loss_box_reg: 0.1708  loss_rpn_cls: 0.0005502  loss_rpn_loc: 0.002282  time: 0.5027  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:24 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 1479  total_loss: 0.1999  loss_cls: 0.0486  loss_box_reg: 0.1401  loss_rpn_cls: 0.0004255  loss_rpn_loc: 0.002044  time: 0.5025  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:34 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1499  total_loss: 0.259  loss_cls: 0.0518  loss_box_reg: 0.2007  loss_rpn_cls: 0.0005833  loss_rpn_loc: 0.002267  time: 0.5023  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:43 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 1519  total_loss: 0.247  loss_cls: 0.0516  loss_box_reg: 0.1697  loss_rpn_cls: 0.001157  loss_rpn_loc: 0.001735  time: 0.5022  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:40:53 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 1539  total_loss: 0.2129  loss_cls: 0.05395  loss_box_reg: 0.1658  loss_rpn_cls: 0.0006602  loss_rpn_loc: 0.002458  time: 0.5020  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:03 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1559  total_loss: 0.2258  loss_cls: 0.05322  loss_box_reg: 0.1571  loss_rpn_cls: 0.0004603  loss_rpn_loc: 0.002249  time: 0.5018  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:13 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 1579  total_loss: 0.2296  loss_cls: 0.05402  loss_box_reg: 0.1457  loss_rpn_cls: 0.0009862  loss_rpn_loc: 0.002429  time: 0.5017  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:23 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 1599  total_loss: 0.1991  loss_cls: 0.07341  loss_box_reg: 0.1529  loss_rpn_cls: 0.001046  loss_rpn_loc: 0.002504  time: 0.5016  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:33 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 1619  total_loss: 0.2049  loss_cls: 0.04676  loss_box_reg: 0.1621  loss_rpn_cls: 0.0002526  loss_rpn_loc: 0.002288  time: 0.5015  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:43 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 1639  total_loss: 0.2179  loss_cls: 0.04938  loss_box_reg: 0.1389  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.001858  time: 0.5016  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:41:53 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1659  total_loss: 0.2472  loss_cls: 0.06786  loss_box_reg: 0.1671  loss_rpn_cls: 0.0003627  loss_rpn_loc: 0.002073  time: 0.5015  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:02 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1679  total_loss: 0.239  loss_cls: 0.05061  loss_box_reg: 0.19  loss_rpn_cls: 0.0004321  loss_rpn_loc: 0.002479  time: 0.5013  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:12 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1699  total_loss: 0.2667  loss_cls: 0.06223  loss_box_reg: 0.1986  loss_rpn_cls: 0.0003747  loss_rpn_loc: 0.002326  time: 0.5012  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:22 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1719  total_loss: 0.2201  loss_cls: 0.06475  loss_box_reg: 0.1632  loss_rpn_cls: 0.00143  loss_rpn_loc: 0.001537  time: 0.5011  data_time: 0.0028  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:32 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1739  total_loss: 0.2312  loss_cls: 0.06912  loss_box_reg: 0.1644  loss_rpn_cls: 0.0009986  loss_rpn_loc: 0.003148  time: 0.5010  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:42 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1759  total_loss: 0.256  loss_cls: 0.05515  loss_box_reg: 0.2038  loss_rpn_cls: 0.0007191  loss_rpn_loc: 0.001908  time: 0.5008  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:42:51 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 1779  total_loss: 0.2174  loss_cls: 0.05819  loss_box_reg: 0.1608  loss_rpn_cls: 0.002616  loss_rpn_loc: 0.001649  time: 0.5007  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:01 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1799  total_loss: 0.2165  loss_cls: 0.05322  loss_box_reg: 0.1754  loss_rpn_cls: 0.0003252  loss_rpn_loc: 0.002426  time: 0.5006  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:11 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 1819  total_loss: 0.2447  loss_cls: 0.05656  loss_box_reg: 0.1715  loss_rpn_cls: 0.001054  loss_rpn_loc: 0.001873  time: 0.5005  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:21 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 1839  total_loss: 0.2541  loss_cls: 0.05985  loss_box_reg: 0.1672  loss_rpn_cls: 0.0004625  loss_rpn_loc: 0.002819  time: 0.5004  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:31 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1859  total_loss: 0.2203  loss_cls: 0.05267  loss_box_reg: 0.1625  loss_rpn_cls: 0.0009332  loss_rpn_loc: 0.002086  time: 0.5003  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:41 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1879  total_loss: 0.2263  loss_cls: 0.04274  loss_box_reg: 0.1698  loss_rpn_cls: 0.0006612  loss_rpn_loc: 0.003368  time: 0.5002  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:43:51 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 1899  total_loss: 0.2183  loss_cls: 0.06167  loss_box_reg: 0.1419  loss_rpn_cls: 0.0008931  loss_rpn_loc: 0.001805  time: 0.5001  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:01 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1919  total_loss: 0.2198  loss_cls: 0.05447  loss_box_reg: 0.1632  loss_rpn_cls: 0.0007103  loss_rpn_loc: 0.002259  time: 0.5000  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:10 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 1939  total_loss: 0.2005  loss_cls: 0.05271  loss_box_reg: 0.1555  loss_rpn_cls: 0.0005455  loss_rpn_loc: 0.001847  time: 0.4997  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:20 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 1959  total_loss: 0.2228  loss_cls: 0.04426  loss_box_reg: 0.1724  loss_rpn_cls: 0.0003971  loss_rpn_loc: 0.002445  time: 0.4995  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:29 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 1979  total_loss: 0.1997  loss_cls: 0.04866  loss_box_reg: 0.1554  loss_rpn_cls: 0.0006408  loss_rpn_loc: 0.00225  time: 0.4994  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:39 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1999  total_loss: 0.2066  loss_cls: 0.0409  loss_box_reg: 0.1575  loss_rpn_cls: 0.0005734  loss_rpn_loc: 0.002157  time: 0.4993  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:49 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2019  total_loss: 0.2558  loss_cls: 0.05872  loss_box_reg: 0.1794  loss_rpn_cls: 0.0009624  loss_rpn_loc: 0.002357  time: 0.4992  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:44:59 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2039  total_loss: 0.1952  loss_cls: 0.04429  loss_box_reg: 0.1514  loss_rpn_cls: 0.0008737  loss_rpn_loc: 0.002624  time: 0.4993  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:09 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 2059  total_loss: 0.2174  loss_cls: 0.05615  loss_box_reg: 0.1611  loss_rpn_cls: 0.0003402  loss_rpn_loc: 0.001924  time: 0.4992  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:19 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2079  total_loss: 0.2264  loss_cls: 0.04116  loss_box_reg: 0.1707  loss_rpn_cls: 0.000361  loss_rpn_loc: 0.001947  time: 0.4991  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:29 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2099  total_loss: 0.2237  loss_cls: 0.05359  loss_box_reg: 0.1625  loss_rpn_cls: 0.0006206  loss_rpn_loc: 0.002123  time: 0.4990  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:39 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 2119  total_loss: 0.1815  loss_cls: 0.04731  loss_box_reg: 0.1295  loss_rpn_cls: 0.0011  loss_rpn_loc: 0.002146  time: 0.4990  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:49 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2139  total_loss: 0.2263  loss_cls: 0.06387  loss_box_reg: 0.1506  loss_rpn_cls: 0.0006828  loss_rpn_loc: 0.002106  time: 0.4989  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:45:58 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 2159  total_loss: 0.2023  loss_cls: 0.04708  loss_box_reg: 0.1692  loss_rpn_cls: 0.0002715  loss_rpn_loc: 0.00201  time: 0.4987  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:46:08 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 2179  total_loss: 0.2474  loss_cls: 0.06167  loss_box_reg: 0.1832  loss_rpn_cls: 0.001117  loss_rpn_loc: 0.002501  time: 0.4987  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:46:19 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 2199  total_loss: 0.211  loss_cls: 0.04217  loss_box_reg: 0.1397  loss_rpn_cls: 0.0005641  loss_rpn_loc: 0.002145  time: 0.4988  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:46:29 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 2219  total_loss: 0.2186  loss_cls: 0.04748  loss_box_reg: 0.1606  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.001881  time: 0.4989  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:46:40 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 2239  total_loss: 0.2191  loss_cls: 0.04631  loss_box_reg: 0.1634  loss_rpn_cls: 0.0006132  loss_rpn_loc: 0.001707  time: 0.4992  data_time: 0.0028  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:46:50 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2259  total_loss: 0.2754  loss_cls: 0.07558  loss_box_reg: 0.1776  loss_rpn_cls: 0.001387  loss_rpn_loc: 0.002255  time: 0.4993  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:01 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 2279  total_loss: 0.2368  loss_cls: 0.05205  loss_box_reg: 0.1676  loss_rpn_cls: 0.001317  loss_rpn_loc: 0.001991  time: 0.4996  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:11 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 2299  total_loss: 0.2277  loss_cls: 0.05892  loss_box_reg: 0.1522  loss_rpn_cls: 0.001787  loss_rpn_loc: 0.001844  time: 0.4997  data_time: 0.0028  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:21 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 2319  total_loss: 0.1904  loss_cls: 0.04137  loss_box_reg: 0.1425  loss_rpn_cls: 0.0003212  loss_rpn_loc: 0.00173  time: 0.4997  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:31 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2339  total_loss: 0.2038  loss_cls: 0.04786  loss_box_reg: 0.1408  loss_rpn_cls: 0.0009691  loss_rpn_loc: 0.001655  time: 0.4997  data_time: 0.0028  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:41 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2359  total_loss: 0.2034  loss_cls: 0.04833  loss_box_reg: 0.1508  loss_rpn_cls: 0.0005338  loss_rpn_loc: 0.001687  time: 0.4995  data_time: 0.0025  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:47:50 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 2379  total_loss: 0.2426  loss_cls: 0.04649  loss_box_reg: 0.1945  loss_rpn_cls: 0.0008401  loss_rpn_loc: 0.002424  time: 0.4995  data_time: 0.0028  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:01 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 2399  total_loss: 0.1982  loss_cls: 0.05896  loss_box_reg: 0.1421  loss_rpn_cls: 0.0006067  loss_rpn_loc: 0.001567  time: 0.4996  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:11 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 2419  total_loss: 0.2104  loss_cls: 0.06218  loss_box_reg: 0.1626  loss_rpn_cls: 0.0004911  loss_rpn_loc: 0.00185  time: 0.4997  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:21 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 2439  total_loss: 0.2109  loss_cls: 0.04003  loss_box_reg: 0.1532  loss_rpn_cls: 0.0002938  loss_rpn_loc: 0.001859  time: 0.4998  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:31 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 2459  total_loss: 0.2211  loss_cls: 0.02893  loss_box_reg: 0.1696  loss_rpn_cls: 0.0003818  loss_rpn_loc: 0.002408  time: 0.4998  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:41 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 2479  total_loss: 0.2189  loss_cls: 0.06312  loss_box_reg: 0.1511  loss_rpn_cls: 0.000594  loss_rpn_loc: 0.002065  time: 0.4998  data_time: 0.0026  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2499  total_loss: 0.2378  loss_cls: 0.0639  loss_box_reg: 0.1822  loss_rpn_cls: 0.0004785  loss_rpn_loc: 0.003139  time: 0.4997  data_time: 0.0027  lr: 0.00025  max_mem: 3364M\n",
      "\u001b[32m[10/12 09:48:52 d2.engine.hooks]: \u001b[0mOverall training speed: 2498 iterations in 0:20:48 (0.4997 s / it)\n",
      "\u001b[32m[10/12 09:48:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:53 (0:00:05 on hooks)\n"
     ]
    }
   ],
   "source": [
    "wandb.init(sync_tensorboard=True,name='baseline')\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_C4_3x.yaml'))\n",
    "cfg.DATASETS.TRAIN = ('data',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_C4_3x.yaml')\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2500\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb56c9f-59ff-4da3-934a-80f00a432684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 09:48:53 d2.evaluation.coco_evaluation]: \u001b[0m'test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[10/12 09:48:53 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'test' to COCO format ...)\n",
      "\u001b[32m[10/12 09:48:53 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/12 09:48:53 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 500, #annotations: 500\n",
      "\u001b[32m[10/12 09:48:53 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/test_coco_format.json' ...\n",
      "\u001b[32m[10/12 09:48:53 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    Card    | 500          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/12 09:48:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 09:48:53 d2.data.common]: \u001b[0mSerializing 500 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 09:48:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.18 MiB\n",
      "\u001b[32m[10/12 09:48:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 500 batches\n",
      "\u001b[32m[10/12 09:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/500. Dataloading: 0.0009 s/iter. Inference: 0.2824 s/iter. Eval: 0.0001 s/iter. Total: 0.2834 s/iter. ETA=0:02:18\n",
      "\u001b[32m[10/12 09:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 30/500. Dataloading: 0.0009 s/iter. Inference: 0.2740 s/iter. Eval: 0.0001 s/iter. Total: 0.2752 s/iter. ETA=0:02:09\n",
      "\u001b[32m[10/12 09:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 49/500. Dataloading: 0.0010 s/iter. Inference: 0.2731 s/iter. Eval: 0.0001 s/iter. Total: 0.2743 s/iter. ETA=0:02:03\n",
      "\u001b[32m[10/12 09:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 68/500. Dataloading: 0.0010 s/iter. Inference: 0.2736 s/iter. Eval: 0.0001 s/iter. Total: 0.2749 s/iter. ETA=0:01:58\n",
      "\u001b[32m[10/12 09:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 87/500. Dataloading: 0.0011 s/iter. Inference: 0.2734 s/iter. Eval: 0.0001 s/iter. Total: 0.2748 s/iter. ETA=0:01:53\n",
      "\u001b[32m[10/12 09:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 106/500. Dataloading: 0.0011 s/iter. Inference: 0.2737 s/iter. Eval: 0.0001 s/iter. Total: 0.2751 s/iter. ETA=0:01:48\n",
      "\u001b[32m[10/12 09:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 124/500. Dataloading: 0.0012 s/iter. Inference: 0.2744 s/iter. Eval: 0.0001 s/iter. Total: 0.2759 s/iter. ETA=0:01:43\n",
      "\u001b[32m[10/12 09:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 143/500. Dataloading: 0.0011 s/iter. Inference: 0.2728 s/iter. Eval: 0.0001 s/iter. Total: 0.2741 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/12 09:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 163/500. Dataloading: 0.0011 s/iter. Inference: 0.2704 s/iter. Eval: 0.0001 s/iter. Total: 0.2718 s/iter. ETA=0:01:31\n",
      "\u001b[32m[10/12 09:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 182/500. Dataloading: 0.0011 s/iter. Inference: 0.2699 s/iter. Eval: 0.0001 s/iter. Total: 0.2712 s/iter. ETA=0:01:26\n",
      "\u001b[32m[10/12 09:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 202/500. Dataloading: 0.0011 s/iter. Inference: 0.2688 s/iter. Eval: 0.0001 s/iter. Total: 0.2701 s/iter. ETA=0:01:20\n",
      "\u001b[32m[10/12 09:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 222/500. Dataloading: 0.0011 s/iter. Inference: 0.2678 s/iter. Eval: 0.0001 s/iter. Total: 0.2691 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/12 09:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 242/500. Dataloading: 0.0011 s/iter. Inference: 0.2669 s/iter. Eval: 0.0001 s/iter. Total: 0.2682 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/12 09:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 262/500. Dataloading: 0.0011 s/iter. Inference: 0.2664 s/iter. Eval: 0.0001 s/iter. Total: 0.2677 s/iter. ETA=0:01:03\n",
      "\u001b[32m[10/12 09:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 282/500. Dataloading: 0.0011 s/iter. Inference: 0.2658 s/iter. Eval: 0.0001 s/iter. Total: 0.2672 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/12 09:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 302/500. Dataloading: 0.0011 s/iter. Inference: 0.2654 s/iter. Eval: 0.0001 s/iter. Total: 0.2667 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 09:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 322/500. Dataloading: 0.0011 s/iter. Inference: 0.2650 s/iter. Eval: 0.0001 s/iter. Total: 0.2663 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 09:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 341/500. Dataloading: 0.0011 s/iter. Inference: 0.2649 s/iter. Eval: 0.0001 s/iter. Total: 0.2662 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 09:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 360/500. Dataloading: 0.0011 s/iter. Inference: 0.2652 s/iter. Eval: 0.0001 s/iter. Total: 0.2665 s/iter. ETA=0:00:37\n",
      "\u001b[32m[10/12 09:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 378/500. Dataloading: 0.0010 s/iter. Inference: 0.2658 s/iter. Eval: 0.0001 s/iter. Total: 0.2671 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/12 09:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 398/500. Dataloading: 0.0010 s/iter. Inference: 0.2655 s/iter. Eval: 0.0001 s/iter. Total: 0.2668 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/12 09:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 418/500. Dataloading: 0.0010 s/iter. Inference: 0.2650 s/iter. Eval: 0.0001 s/iter. Total: 0.2663 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 09:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 438/500. Dataloading: 0.0010 s/iter. Inference: 0.2647 s/iter. Eval: 0.0001 s/iter. Total: 0.2660 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 09:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 458/500. Dataloading: 0.0010 s/iter. Inference: 0.2643 s/iter. Eval: 0.0001 s/iter. Total: 0.2656 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 09:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 478/500. Dataloading: 0.0010 s/iter. Inference: 0.2640 s/iter. Eval: 0.0001 s/iter. Total: 0.2653 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/12 09:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 498/500. Dataloading: 0.0010 s/iter. Inference: 0.2637 s/iter. Eval: 0.0001 s/iter. Total: 0.2650 s/iter. ETA=0:00:00\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:11.200330 (0.265051 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:10 (0.263630 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.029 | 59.470 | 51.040 | 26.364 | 41.805 | 49.280 |\n"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg,\"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1633954e-dd6d-4fb0-88aa-6d9a234e12d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 09:51:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 09:51:06 d2.data.common]: \u001b[0mSerializing 500 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 09:51:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.18 MiB\n",
      "\u001b[32m[10/12 09:51:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 500 batches\n",
      "\u001b[32m[10/12 09:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 14/500. Dataloading: 0.0008 s/iter. Inference: 0.2596 s/iter. Eval: 0.0001 s/iter. Total: 0.2606 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/12 09:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 33/500. Dataloading: 0.0010 s/iter. Inference: 0.2638 s/iter. Eval: 0.0001 s/iter. Total: 0.2651 s/iter. ETA=0:02:03\n",
      "\u001b[32m[10/12 09:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 52/500. Dataloading: 0.0010 s/iter. Inference: 0.2643 s/iter. Eval: 0.0001 s/iter. Total: 0.2655 s/iter. ETA=0:01:58\n",
      "\u001b[32m[10/12 09:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 71/500. Dataloading: 0.0010 s/iter. Inference: 0.2638 s/iter. Eval: 0.0001 s/iter. Total: 0.2650 s/iter. ETA=0:01:53\n",
      "\u001b[32m[10/12 09:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 90/500. Dataloading: 0.0010 s/iter. Inference: 0.2635 s/iter. Eval: 0.0001 s/iter. Total: 0.2647 s/iter. ETA=0:01:48\n",
      "\u001b[32m[10/12 09:51:36 d2.evaluation.evaluator]: \u001b[0mInference done 110/500. Dataloading: 0.0010 s/iter. Inference: 0.2623 s/iter. Eval: 0.0001 s/iter. Total: 0.2635 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/12 09:51:41 d2.evaluation.evaluator]: \u001b[0mInference done 130/500. Dataloading: 0.0010 s/iter. Inference: 0.2617 s/iter. Eval: 0.0001 s/iter. Total: 0.2629 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/12 09:51:46 d2.evaluation.evaluator]: \u001b[0mInference done 150/500. Dataloading: 0.0010 s/iter. Inference: 0.2608 s/iter. Eval: 0.0001 s/iter. Total: 0.2620 s/iter. ETA=0:01:31\n",
      "\u001b[32m[10/12 09:51:51 d2.evaluation.evaluator]: \u001b[0mInference done 170/500. Dataloading: 0.0010 s/iter. Inference: 0.2602 s/iter. Eval: 0.0001 s/iter. Total: 0.2614 s/iter. ETA=0:01:26\n",
      "\u001b[32m[10/12 09:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 190/500. Dataloading: 0.0010 s/iter. Inference: 0.2597 s/iter. Eval: 0.0001 s/iter. Total: 0.2609 s/iter. ETA=0:01:20\n",
      "\u001b[32m[10/12 09:52:01 d2.evaluation.evaluator]: \u001b[0mInference done 210/500. Dataloading: 0.0010 s/iter. Inference: 0.2593 s/iter. Eval: 0.0001 s/iter. Total: 0.2605 s/iter. ETA=0:01:15\n",
      "\u001b[32m[10/12 09:52:06 d2.evaluation.evaluator]: \u001b[0mInference done 230/500. Dataloading: 0.0010 s/iter. Inference: 0.2592 s/iter. Eval: 0.0001 s/iter. Total: 0.2604 s/iter. ETA=0:01:10\n",
      "\u001b[32m[10/12 09:52:12 d2.evaluation.evaluator]: \u001b[0mInference done 250/500. Dataloading: 0.0010 s/iter. Inference: 0.2590 s/iter. Eval: 0.0001 s/iter. Total: 0.2602 s/iter. ETA=0:01:05\n",
      "\u001b[32m[10/12 09:52:17 d2.evaluation.evaluator]: \u001b[0mInference done 270/500. Dataloading: 0.0010 s/iter. Inference: 0.2589 s/iter. Eval: 0.0001 s/iter. Total: 0.2601 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/12 09:52:22 d2.evaluation.evaluator]: \u001b[0mInference done 290/500. Dataloading: 0.0010 s/iter. Inference: 0.2588 s/iter. Eval: 0.0001 s/iter. Total: 0.2600 s/iter. ETA=0:00:54\n",
      "\u001b[32m[10/12 09:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 310/500. Dataloading: 0.0010 s/iter. Inference: 0.2586 s/iter. Eval: 0.0001 s/iter. Total: 0.2598 s/iter. ETA=0:00:49\n",
      "\u001b[32m[10/12 09:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 330/500. Dataloading: 0.0010 s/iter. Inference: 0.2584 s/iter. Eval: 0.0001 s/iter. Total: 0.2597 s/iter. ETA=0:00:44\n",
      "\u001b[32m[10/12 09:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 350/500. Dataloading: 0.0010 s/iter. Inference: 0.2583 s/iter. Eval: 0.0001 s/iter. Total: 0.2595 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/12 09:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 370/500. Dataloading: 0.0010 s/iter. Inference: 0.2583 s/iter. Eval: 0.0001 s/iter. Total: 0.2595 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/12 09:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 390/500. Dataloading: 0.0010 s/iter. Inference: 0.2582 s/iter. Eval: 0.0001 s/iter. Total: 0.2594 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/12 09:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 410/500. Dataloading: 0.0010 s/iter. Inference: 0.2581 s/iter. Eval: 0.0001 s/iter. Total: 0.2593 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/12 09:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 430/500. Dataloading: 0.0010 s/iter. Inference: 0.2580 s/iter. Eval: 0.0001 s/iter. Total: 0.2592 s/iter. ETA=0:00:18\n",
      "\u001b[32m[10/12 09:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 450/500. Dataloading: 0.0010 s/iter. Inference: 0.2579 s/iter. Eval: 0.0001 s/iter. Total: 0.2591 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/12 09:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 470/500. Dataloading: 0.0010 s/iter. Inference: 0.2579 s/iter. Eval: 0.0001 s/iter. Total: 0.2591 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/12 09:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 490/500. Dataloading: 0.0010 s/iter. Inference: 0.2578 s/iter. Eval: 0.0001 s/iter. Total: 0.2590 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.244595 (0.259080 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:07 (0.257747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
      "\u001b[32m[10/12 09:53:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.029 | 59.470 | 51.040 | 26.364 | 41.805 | 49.280 |\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg,\"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce41a73e-dd86-4161-9089-445d9241266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 09:53:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 09:53:17 d2.data.common]: \u001b[0mSerializing 500 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 09:53:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.18 MiB\n",
      "\u001b[32m[10/12 09:53:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 500 batches\n",
      "\u001b[32m[10/12 09:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/500. Dataloading: 0.0008 s/iter. Inference: 0.2576 s/iter. Eval: 0.0001 s/iter. Total: 0.2586 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/12 09:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 31/500. Dataloading: 0.0010 s/iter. Inference: 0.2571 s/iter. Eval: 0.0001 s/iter. Total: 0.2583 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/12 09:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 51/500. Dataloading: 0.0010 s/iter. Inference: 0.2577 s/iter. Eval: 0.0001 s/iter. Total: 0.2589 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/12 09:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 71/500. Dataloading: 0.0010 s/iter. Inference: 0.2575 s/iter. Eval: 0.0001 s/iter. Total: 0.2587 s/iter. ETA=0:01:50\n",
      "\u001b[32m[10/12 09:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 91/500. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/12 09:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 111/500. Dataloading: 0.0010 s/iter. Inference: 0.2567 s/iter. Eval: 0.0001 s/iter. Total: 0.2579 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/12 09:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 131/500. Dataloading: 0.0010 s/iter. Inference: 0.2566 s/iter. Eval: 0.0001 s/iter. Total: 0.2578 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/12 09:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 151/500. Dataloading: 0.0010 s/iter. Inference: 0.2565 s/iter. Eval: 0.0001 s/iter. Total: 0.2577 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/12 09:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 171/500. Dataloading: 0.0010 s/iter. Inference: 0.2565 s/iter. Eval: 0.0001 s/iter. Total: 0.2577 s/iter. ETA=0:01:24\n",
      "\u001b[32m[10/12 09:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 191/500. Dataloading: 0.0010 s/iter. Inference: 0.2566 s/iter. Eval: 0.0001 s/iter. Total: 0.2578 s/iter. ETA=0:01:19\n",
      "\u001b[32m[10/12 09:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 211/500. Dataloading: 0.0010 s/iter. Inference: 0.2567 s/iter. Eval: 0.0001 s/iter. Total: 0.2579 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/12 09:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 231/500. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/12 09:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 251/500. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/12 09:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 271/500. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/12 09:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 291/500. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/12 09:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 311/500. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/12 09:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 331/500. Dataloading: 0.0010 s/iter. Inference: 0.2569 s/iter. Eval: 0.0001 s/iter. Total: 0.2581 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/12 09:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 351/500. Dataloading: 0.0010 s/iter. Inference: 0.2570 s/iter. Eval: 0.0001 s/iter. Total: 0.2582 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/12 09:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 371/500. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2580 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/12 09:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 391/500. Dataloading: 0.0010 s/iter. Inference: 0.2568 s/iter. Eval: 0.0001 s/iter. Total: 0.2579 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/12 09:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 411/500. Dataloading: 0.0010 s/iter. Inference: 0.2567 s/iter. Eval: 0.0001 s/iter. Total: 0.2579 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/12 09:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 431/500. Dataloading: 0.0010 s/iter. Inference: 0.2566 s/iter. Eval: 0.0001 s/iter. Total: 0.2578 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/12 09:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 451/500. Dataloading: 0.0010 s/iter. Inference: 0.2566 s/iter. Eval: 0.0001 s/iter. Total: 0.2578 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/12 09:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 471/500. Dataloading: 0.0010 s/iter. Inference: 0.2565 s/iter. Eval: 0.0001 s/iter. Total: 0.2577 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/12 09:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 491/500. Dataloading: 0.0010 s/iter. Inference: 0.2565 s/iter. Eval: 0.0001 s/iter. Total: 0.2577 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:07.611273 (0.257801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:06 (0.256455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
      "\u001b[32m[10/12 09:55:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.029 | 59.470 | 51.040 | 26.364 | 41.805 | 49.280 |\n"
     ]
    }
   ],
   "source": [
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg,\"test\")\n",
    "metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c39980-5326-4574-95b8-44c63e2191ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test_imgs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61583/232556925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test_imgs/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./test_imgs/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     v = v.draw_instance_predictions(\n\u001b[1;32m      4\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./test_imgs/{img}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test_imgs/'"
     ]
    }
   ],
   "source": [
    "for img in os.listdir(\"./test_imgs/\"):\n",
    "    v = Visualizer(cv2.imread(f\"./test_imgs/{img}\")[:, :, ::-1], metadata=metadata)\n",
    "    v = v.draw_instance_predictions(\n",
    "        predictor(cv2.imread(f\"./test_imgs/{img}\"))[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    v = v.get_image()[:, :, ::-1]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(v)\n",
    "    plt.savefig(\"./img.png\")\n",
    "    plt.close()\n",
    "    wandb.log({f\"Img/{img}\": wandb.Image(cv2.imread(\"./img.png\"))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fa8df-3434-4391-a4e9-1f80d19a04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = COCOEvaluator(\"data\", output_dir=\"./output\")\n",
    "# val_loader = build_detection_test_loader(cfg,\"data\")\n",
    "# metrics = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "# wandb.log(metrics)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16371c90-da8a-4b09-a711-d0d24dfee086",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TENSORBOARD_BINARY'] = '/path/to/envs/my_env/bin/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409f51f-f9ba-48b4-95d5-b23624e56778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04d347-00aa-41b0-ba09-355d1c91e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1400813-6daf-4186-b937-60c99756830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42155b-5846-4de2-a7c6-ddda3138f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir outputs # TODO : remove this this is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f1837-7aa9-4daa-9e9f-c1a457594f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcc5d8-12fe-43a6-a53b-8a74b60c5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da9eb0-a360-4336-98d7-360fa420e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49332f8c-54d1-4dd7-92b8-35b226dffdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c8fe6-bbb3-4148-a0e0-336bd7370ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fbc0d-ed89-49a2-9549-03a4728645f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"data\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"data\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a6290-c3b9-431e-95dc-bb03fb527a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_C4_3x.yaml'))\n",
    "cfg.DATASETS.TRAIN = ('data',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2500\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f279e-47e6-4a61-9895-5021b0164f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdad0e-8f73-4d13-83bc-c564cdc38617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"data\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"data\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9131806-d4b6-4f02-a4fc-a17cb0576094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd0f5712b28ab533ddcd3a93c4a815f0ece6a0b0b411aefcf33cd4d282335a68ea6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
